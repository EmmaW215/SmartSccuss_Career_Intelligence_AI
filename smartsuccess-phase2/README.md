# SmartSuccess.AI Interview Backend - Phase 2

## ğŸ¯ Overview

Cost-optimized AI interview platform with natural conversation capabilities.

**Monthly Cost: $0-10** (vs. original $55-75)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ARCHITECTURE OVERVIEW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Render Free ($0)        GPU Server (è‡ªæ‰˜ç®¡)      Gemini ($0-8) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ è½»é‡ API     â”‚ â—„â”€â”€â”€â–º â”‚ Whisper STT  â”‚       â”‚ 2.0 Flash  â”‚  â”‚
â”‚  â”‚ é—®é¢˜åº“       â”‚       â”‚ XTTS TTS     â”‚ â—„â”€â”€â”€â–º â”‚ 1.5 Flash  â”‚  â”‚
â”‚  â”‚ Session ç®¡ç† â”‚       â”‚ Custom RAG   â”‚       â”‚ (å¯¹è¯å¤„ç†)  â”‚  â”‚
â”‚  â”‚ æ–‡å­—å¤‡ç”¨æ¨¡å¼ â”‚       â”‚ Embeddings   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Cost Breakdown

| Component | Cost | Notes |
|-----------|------|-------|
| Render Free | $0 | Lightweight API, 512MB RAM |
| Gemini API | $0-8 | Free tier: 1500 req/day |
| GPU Server | Electricity | Self-hosted Whisper + XTTS |
| Edge-TTS | $0 | Free Microsoft TTS fallback |
| **Total** | **$0-10/month** | |

## ğŸš€ Quick Start

### 1. Deploy to Render (FREE)

[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy)

Or manually:

```bash
# Clone and deploy
cd render-backend
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### 2. Configure Environment

```bash
# Copy example env
cp .env.example .env

# Set your Gemini API key (FREE at https://makersuite.google.com/app/apikey)
GEMINI_API_KEY=your_key_here

# Optional: GPU server URL
GPU_SERVER_URL=http://your-gpu:8001
```

### 3. Test the API

```bash
# Health check
curl http://localhost:8000/health

# Start screening interview
curl -X POST http://localhost:8000/api/interview/screening/start \
  -H "Content-Type: application/json" \
  -d '{"user_id": "test123", "user_name": "Emma"}'
```

## ğŸ“ Project Structure

```
smartsuccess-phase2/
â”œâ”€â”€ render-backend/           # Render Free deployment
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â””â”€â”€ conversation_engine.py  # Natural AI conversations
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py         # Gemini/OpenAI integration
â”‚   â”‚   â”‚   â”œâ”€â”€ gpu_client.py          # GPU server client
â”‚   â”‚   â”‚   â””â”€â”€ session_store.py       # In-memory sessions
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ question_bank.py       # Pre-built questions
â”‚   â”‚   â”‚   â””â”€â”€ custom_rag_builder.py  # Custom RAG
â”‚   â”‚   â”œâ”€â”€ feedback/
â”‚   â”‚   â”‚   â””â”€â”€ feedback_generator.py  # Interview feedback
â”‚   â”‚   â””â”€â”€ api/routes/
â”‚   â”‚       â”œâ”€â”€ screening.py
â”‚   â”‚       â”œâ”€â”€ behavioral.py
â”‚   â”‚       â”œâ”€â”€ technical.py
â”‚   â”‚       â”œâ”€â”€ customize.py
â”‚   â”‚       â”œâ”€â”€ voice.py
â”‚   â”‚       â””â”€â”€ dashboard.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ render.yaml
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ gpu-server/              # Self-hosted GPU (optional)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ whisper_service.py  # STT
â”‚   â”‚   â”œâ”€â”€ tts_service.py      # XTTS
â”‚   â”‚   â””â”€â”€ rag_service.py      # RAG building
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend-components/     # React components
    â”œâ”€â”€ components/
    â”‚   â””â”€â”€ interview/
    â”‚       â””â”€â”€ InterviewVoicePanel.tsx
    â”œâ”€â”€ hooks/
    â”‚   â”œâ”€â”€ useMicrophone.ts
    â”‚   â”œâ”€â”€ useAudioPlayer.ts
    â”‚   â””â”€â”€ useInterviewSession.ts
    â””â”€â”€ services/
        â””â”€â”€ interviewApi.ts
```

## ğŸ¤ Interview Types

### 1. Screening Interview
- 5 questions, ~15 minutes
- Basic fit and motivation
- Route: `/api/interview/screening`

### 2. Behavioral Interview
- 6 questions, ~30 minutes
- STAR method evaluation
- Route: `/api/interview/behavioral`

### 3. Technical Interview
- 8 questions, ~45 minutes
- System design, coding, problem-solving
- Route: `/api/interview/technical`

### 4. Customize Interview (Requires GPU)
- 10 questions, ~45 minutes
- Personalized from uploaded documents
- Route: `/api/interview/customize`

## ğŸ”§ API Reference

### Start Interview
```http
POST /api/interview/{type}/start
Content-Type: application/json

{
  "user_id": "string",
  "user_name": "string (optional)",
  "voice_enabled": true
}
```

### Submit Response
```http
POST /api/interview/{type}/respond
Content-Type: application/json

{
  "session_id": "string",
  "user_response": "string"
}
```

### Voice Services
```http
# Transcribe audio
POST /api/voice/transcribe
Content-Type: multipart/form-data
audio: <file>
language: "en"

# Synthesize speech
POST /api/voice/synthesize
Content-Type: application/json
{
  "text": "Hello, this is Alex.",
  "voice": "professional"
}
```

## ğŸ’¡ Graceful Degradation

| GPU Status | Voice | Custom RAG | Standard Interviews |
|------------|-------|------------|---------------------|
| âœ… Online | High-quality | âœ… Full | âœ… Voice + Text |
| âŒ Offline | Edge-TTS | âŒ Disabled | âœ… Text only |

## ğŸ”’ Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GEMINI_API_KEY` | Yes | Gemini API key (free tier) |
| `GPU_SERVER_URL` | No | Self-hosted GPU server URL |
| `OPENAI_API_KEY` | No | Emergency fallback |
| `ENVIRONMENT` | No | `production` or `development` |

## ğŸ“ˆ LLM Provider Priority

1. **Gemini 2.0 Flash** - FREE (1500 req/day)
2. **Gemini 1.5 Flash** - $0.075/1M tokens
3. **GPT-4o-mini** - $0.15/1M tokens (emergency)

## ğŸ–¥ï¸ GPU Server Setup (Optional)

```bash
cd gpu-server

# Install dependencies (requires CUDA)
pip install -r requirements.txt

# Run server
uvicorn main:app --host 0.0.0.0 --port 8001
```

Required GPU: NVIDIA with 8GB+ VRAM (RTX 3070 or better)

## ğŸ› ï¸ Development

```bash
# Install dependencies
cd render-backend
pip install -r requirements.txt

# Run with hot reload
uvicorn app.main:app --reload --port 8000

# Test
pytest tests/
```

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Open Pull Request
